{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":90489,"databundleVersionId":10898385,"sourceType":"competition"}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# import numpy as np # linear algebra\n# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-16T21:15:19.094843Z","iopub.execute_input":"2025-03-16T21:15:19.095200Z","iopub.status.idle":"2025-03-16T21:15:19.099810Z","shell.execute_reply.started":"2025-03-16T21:15:19.095167Z","shell.execute_reply":"2025-03-16T21:15:19.098792Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# A Simple Starter Code for the AJL Competition\n\n@Cindy Deng\n\n---\n\n\nHi! This starter code is designed to help you get familiar with basic Kaggle operations and guide you through the basic workflow of a machine learning project. \n\nThe code outlines essential steps including data loading, preprocessing, model building, training, and generating predictions. Each section serves as a foundation, but there are many ways to enhance each step to improve your final model's accuracy. Feel free to experiment with different data augmentation techniques, model architectures, and tuning methods to optimize your final results! Some amazing tutorials are available through your AI Studio course in Canvas / in the 'Resource' section of this Kaggle competition.\n\nGood luck and have fun!\n\n---","metadata":{}},{"cell_type":"markdown","source":"## Note - About file path\n\nYou could use the cell above to print the names of the file directories and get the following directories:\n\n```\n/kaggle/input/bttai-ajl-2025/sample_submission.csv\n/kaggle/input/bttai-ajl-2025/train.csv\n/kaggle/input/bttai-ajl-2025/test.csv\n/kaggle/input/bttai-ajl-2025/test/test/e0374ae6c1362ff183cfba28ded5421b.jpg\n/kaggle/input/bttai-ajl-2025/test/test/437159c605260bdd079af230566af291.jpg\n...\n...\n/kaggle/input/bttai-ajl-2025/train/train/dermatomyositis/11271bdf2598afdd4260db3125e1f6a5.jpg\n/kaggle/input/bttai-ajl-2025/train/train/dermatomyositis/732819951dcf2b53d15ea7b8bb123b71.jpg\n/kaggle/input/bttai-ajl-2025/train/train/dermatomyositis/6dcc7a8abb5e1c6e670101f4b6231246.jpg\n/kaggle/input/bttai-ajl-2025/train/train/dermatomyositis/e63c3b3f0ab8905e204fe467cc7411f9.jpg\n...\n...\n```\n\n","metadata":{}},{"cell_type":"markdown","source":"## 1. Import Necessary Libraries","metadata":{}},{"cell_type":"code","source":"# 1. Import Necessary Libraries\nimport pandas as pd\nimport numpy as np\nimport os\nimport tensorflow as tf\nimport keras\nfrom keras import layers\nfrom keras.layers import Conv2D,MaxPool2D,Dense,Flatten,BatchNormalization,Dropout, Input\nfrom keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping\nimport matplotlib.pyplot as plt\n\n# Explanation:\n# - pandas and numpy: for data manipulation\n# - sklearn: for splitting data and encoding labels\n# - tensorflow.keras: for building and training the neural network","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T21:15:19.609717Z","iopub.execute_input":"2025-03-16T21:15:19.610038Z","iopub.status.idle":"2025-03-16T21:15:36.564770Z","shell.execute_reply.started":"2025-03-16T21:15:19.610013Z","shell.execute_reply":"2025-03-16T21:15:36.563699Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Load Data\n\nMake sure to verify the file paths if you're running on a different platform.","metadata":{}},{"cell_type":"code","source":"# 2. Load Data\ntrain_df = pd.read_csv('/kaggle/input/bttai-ajl-2025/train.csv')\ntest_df = pd.read_csv('/kaggle/input/bttai-ajl-2025/test.csv')\n\n# Add .jpg extension to md5hash column to reference the file_name\ntrain_df['md5hash'] = train_df['md5hash'].astype(str) + '.jpg'\ntest_df['md5hash'] = test_df['md5hash'].astype(str) + '.jpg'\n\n# Combine label and md5hash to form the correct path\ntrain_df['file_path'] = train_df['label'] + '/' + train_df['md5hash']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T21:15:36.566033Z","iopub.execute_input":"2025-03-16T21:15:36.566656Z","iopub.status.idle":"2025-03-16T21:15:36.615666Z","shell.execute_reply.started":"2025-03-16T21:15:36.566626Z","shell.execute_reply":"2025-03-16T21:15:36.614583Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Check the first few rows to understand the structure\nprint(train_df.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T21:15:36.617615Z","iopub.execute_input":"2025-03-16T21:15:36.618002Z","iopub.status.idle":"2025-03-16T21:15:36.633598Z","shell.execute_reply.started":"2025-03-16T21:15:36.617967Z","shell.execute_reply":"2025-03-16T21:15:36.632151Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#get column distributions\ntrain_df.columns","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T21:15:36.635160Z","iopub.execute_input":"2025-03-16T21:15:36.635636Z","iopub.status.idle":"2025-03-16T21:15:36.646526Z","shell.execute_reply.started":"2025-03-16T21:15:36.635590Z","shell.execute_reply":"2025-03-16T21:15:36.645223Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df[\"fitzpatrick_scale\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T21:15:36.647724Z","iopub.execute_input":"2025-03-16T21:15:36.648025Z","iopub.status.idle":"2025-03-16T21:15:36.672658Z","shell.execute_reply.started":"2025-03-16T21:15:36.648000Z","shell.execute_reply":"2025-03-16T21:15:36.671345Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df[\"fitzpatrick_centaur\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T21:15:36.673757Z","iopub.execute_input":"2025-03-16T21:15:36.674153Z","iopub.status.idle":"2025-03-16T21:15:36.693295Z","shell.execute_reply.started":"2025-03-16T21:15:36.674116Z","shell.execute_reply":"2025-03-16T21:15:36.691834Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df[\"label\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T21:15:36.694549Z","iopub.execute_input":"2025-03-16T21:15:36.694935Z","iopub.status.idle":"2025-03-16T21:15:36.716895Z","shell.execute_reply.started":"2025-03-16T21:15:36.694904Z","shell.execute_reply":"2025-03-16T21:15:36.715523Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df[\"nine_partition_label\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T21:15:36.719408Z","iopub.execute_input":"2025-03-16T21:15:36.719794Z","iopub.status.idle":"2025-03-16T21:15:36.738713Z","shell.execute_reply.started":"2025-03-16T21:15:36.719762Z","shell.execute_reply":"2025-03-16T21:15:36.737271Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df[\"three_partition_label\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T13:43:50.436025Z","iopub.execute_input":"2025-03-16T13:43:50.436382Z","iopub.status.idle":"2025-03-16T13:43:50.452363Z","shell.execute_reply.started":"2025-03-16T13:43:50.436333Z","shell.execute_reply":"2025-03-16T13:43:50.451356Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df[\"qc\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T13:43:50.453388Z","iopub.execute_input":"2025-03-16T13:43:50.453754Z","iopub.status.idle":"2025-03-16T13:43:50.471401Z","shell.execute_reply.started":"2025-03-16T13:43:50.453727Z","shell.execute_reply":"2025-03-16T13:43:50.470569Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_df[\"ddi_scale\"].value_counts()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T13:43:50.472364Z","iopub.execute_input":"2025-03-16T13:43:50.472740Z","iopub.status.idle":"2025-03-16T13:43:50.490597Z","shell.execute_reply.started":"2025-03-16T13:43:50.472699Z","shell.execute_reply":"2025-03-16T13:43:50.489561Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Data Preprocessing\n\n\nThis section demonstrates basic preprocessing techniques. To enhance data quality and model performance, consider incorporating more advanced preprocessing methods.\n\nFor further guidance, feel free to take a look at the [Image Preprocessing tutorial](https://colab.research.google.com/drive/1-ItNcRMbZBE6BCwPT-wD8m3YmHqwHxme?usp=sharing)  available in the 'Resources' section of this Kaggle competition.\n","metadata":{}},{"cell_type":"markdown","source":"# 3. Data Preprocessing\n# Encode the labels\nlabel_encoder = LabelEncoder()\ntrain_df['encoded_label'] = label_encoder.fit_transform(train_df['label'])\n\n# Split the data into training and validation sets\ntrain_data, val_data = train_test_split(train_df, test_size=0.2, random_state=42)\n\n# Define image data generators for training and validation\ntrain_datagen = ImageDataGenerator(rescale=1./255)\nval_datagen = ImageDataGenerator(rescale=1./255)\n\n# Define the directory paths\ntrain_dir = '/kaggle/input/bttai-ajl-2025/train/train/'","metadata":{}},{"cell_type":"code","source":"image_size=(128, 128)\nbatch_size=32\ndata_dir = \"/kaggle/input/bttai-ajl-2025/train/train/\"\ntrain_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=image_size,\n  batch_size=batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T21:16:25.024228Z","iopub.execute_input":"2025-03-16T21:16:25.024690Z","iopub.status.idle":"2025-03-16T21:16:25.358024Z","shell.execute_reply.started":"2025-03-16T21:16:25.024659Z","shell.execute_reply":"2025-03-16T21:16:25.356825Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"val_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=123,\n  image_size=image_size,\n  batch_size=batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T21:16:26.618159Z","iopub.execute_input":"2025-03-16T21:16:26.618646Z","iopub.status.idle":"2025-03-16T21:16:26.849017Z","shell.execute_reply.started":"2025-03-16T21:16:26.618610Z","shell.execute_reply":"2025-03-16T21:16:26.847837Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class_names = train_ds.class_names\nprint(class_names)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T13:43:56.958284Z","iopub.execute_input":"2025-03-16T13:43:56.958689Z","iopub.status.idle":"2025-03-16T13:43:56.964075Z","shell.execute_reply.started":"2025-03-16T13:43:56.958657Z","shell.execute_reply":"2025-03-16T13:43:56.962947Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T13:43:57.340197Z","iopub.execute_input":"2025-03-16T13:43:57.340601Z","iopub.status.idle":"2025-03-16T13:43:58.744667Z","shell.execute_reply.started":"2025-03-16T13:43:57.340568Z","shell.execute_reply":"2025-03-16T13:43:58.743309Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"normalization_layer = tf.keras.layers.Rescaling(1./255)\nnormalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\nimage_batch, labels_batch = next(iter(normalized_ds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T21:25:43.669295Z","iopub.execute_input":"2025-03-10T21:25:43.669837Z","iopub.status.idle":"2025-03-10T21:25:43.859876Z","shell.execute_reply.started":"2025-03-10T21:25:43.669774Z","shell.execute_reply":"2025-03-10T21:25:43.858672Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T21:25:43.863715Z","iopub.execute_input":"2025-03-10T21:25:43.864067Z","iopub.status.idle":"2025-03-10T21:25:43.880482Z","shell.execute_reply.started":"2025-03-10T21:25:43.864039Z","shell.execute_reply":"2025-03-10T21:25:43.879342Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Build the model\n","metadata":{}},{"cell_type":"code","source":"# TODO: You should implement the model architecture here.\n# Feel free to explore different model types that best serve your purpose.\ndef make_model(input_shape, num_classes):\n    inputs = keras.Input(shape=input_shape)\n    # Define the input layer with the specified shape.\n\n    # Entry block\n    #x = layers.Rescaling(1.0 / 255)(inputs)\n    # Rescale pixel values from [0, 255] to [0, 1] by dividing by 255 for normalization.\n    x = inputs\n\n    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n    # Apply a convolutional layer with 128 filters, a 3x3 kernel, stride of 2, and \"same\" padding.\n    # This reduces the spatial dimensions of the input image.\n\n    x = layers.BatchNormalization()(x)\n    # Normalize the activations from the previous layer to stabilize and accelerate training.\n\n    x = layers.Activation(\"relu\")(x)\n    # Apply ReLU (Rectified Linear Unit) activation to introduce non-linearity.\n\n    previous_block_activation = x\n    # Save the output of the entry block for residual connections.\n\n    for size in [256, 512, 728]:\n        # Loop through a series of blocks with increasing filter sizes (256, 512, 728).\n\n        x = layers.Activation(\"relu\")(x)\n        # Apply ReLU activation to the current block's input.\n\n        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n        # Apply a depthwise separable convolution with the specified number of filters and 3x3 kernel.\n\n        x = layers.BatchNormalization()(x)\n        # Normalize the activations after the convolution.\n\n        x = layers.Activation(\"relu\")(x)\n        # Apply ReLU activation again.\n\n        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n        # Apply another depthwise separable convolution with the same filter size.\n\n        x = layers.BatchNormalization()(x)\n        # Normalize the activations again.\n\n        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n        # Apply a 3x3 max pooling layer with a stride of 2 to reduce the spatial dimensions.\n\n        # Project residual\n        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n            previous_block_activation\n        )\n        # Apply a 1x1 convolution to the previous block's output to match dimensions for addition.\n\n        x = layers.add([x, residual])\n        # Add the residual connection to the current block's output.\n\n        previous_block_activation = x\n        # Update the residual reference for the next block.\n\n    x = layers.SeparableConv2D(1024, 3, padding=\"same\")(x)\n    # Apply a depthwise separable convolution with 1024 filters and 3x3 kernel.\n\n    x = layers.BatchNormalization()(x)\n    # Normalize the activations.\n\n    x = layers.Activation(\"relu\")(x)\n    # Apply ReLU activation.\n\n    x = layers.GlobalAveragePooling2D()(x)\n    # Apply global average pooling to reduce each feature map to a single value.\n\n    if num_classes == 2:\n        units = 1\n        # If it's a binary classification task, the output layer will have one unit.\n    else:\n        units = num_classes\n        # For multi-class classification, the output layer will have one unit per class.\n\n    x = layers.Dropout(0.25)(x)\n    # Apply dropout with a rate of 25% to reduce overfitting.\n\n    outputs = layers.Dense(units, activation=None)(x)\n    # Define the output layer with `units` neurons. No activation is applied here (logits are returned).\n\n    return keras.Model(inputs, outputs)\n    # Create and return the Keras model.\n\n# Create the model instance.\nmodel = make_model(input_shape=image_size + (3,), num_classes=2)\n# Call `make_model` with input shape (180, 180, 3) (for RGB images) and binary classification (2 classes).\n\nkeras.utils.plot_model(model, show_shapes=True)\n# Visualize the model's architecture with layer shapes using Keras's plot_model utility.\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T21:25:43.882057Z","iopub.execute_input":"2025-03-10T21:25:43.882391Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Train the Model\n","metadata":{}},{"cell_type":"code","source":"# TODO: Train your model here.\nepochs = 12\n\ncallbacks = [\n    keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.keras\"),\n]\nmodel.compile(\n    optimizer=keras.optimizers.Adam(3e-4),\n    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n    metrics=[keras.metrics.BinaryAccuracy(name=\"acc\")],\n)\nmodel.fit(\n    train_ds,\n    epochs=epochs,\n    callbacks=callbacks,\n    validation_data=val_ds,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T21:25:46.891970Z","iopub.execute_input":"2025-03-10T21:25:46.892399Z","iopub.status.idle":"2025-03-10T22:53:02.022687Z","shell.execute_reply.started":"2025-03-10T21:25:46.892351Z","shell.execute_reply":"2025-03-10T22:53:02.021511Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#save model\nmodel.save('/kaggle/working/pls_save.keras')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T23:19:51.355632Z","iopub.execute_input":"2025-03-10T23:19:51.356021Z","iopub.status.idle":"2025-03-10T23:19:51.598672Z","shell.execute_reply.started":"2025-03-10T23:19:51.355986Z","shell.execute_reply":"2025-03-10T23:19:51.597622Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#load model\ns_model = keras.models.load_model('/kaggle/working/prelim_model.keras')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T21:16:04.147631Z","iopub.execute_input":"2025-03-16T21:16:04.148014Z","iopub.status.idle":"2025-03-16T21:16:04.623667Z","shell.execute_reply.started":"2025-03-16T21:16:04.147987Z","shell.execute_reply":"2025-03-16T21:16:04.622370Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Make Predictions on Test Data","metadata":{}},{"cell_type":"code","source":"# 6. Make Predictions on Test Data\ndef preprocess_test_data(test_df, directory):\n    \"\"\"\n    Template for loading and preprocessing test images.\n    \"\"\"\n    # TODO: create a generator for the test set here.\n    test_datagen = ImageDataGenerator(rescale=1./255)\n    test_generator = test_datagen.flow_from_dataframe(\n        dataframe=test_df,\n        directory='/kaggle/input/bttai-ajl-2025/test/test/',\n        x_col=\"file_path\",\n        target_size=image_size,\n        batch_size=batch_size,\n        class_mode=None,\n        shuffle=False\n    )\n    return test_generator\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T13:50:47.240818Z","iopub.execute_input":"2025-03-16T13:50:47.241198Z","iopub.status.idle":"2025-03-16T13:50:47.246719Z","shell.execute_reply.started":"2025-03-16T13:50:47.241173Z","shell.execute_reply":"2025-03-16T13:50:47.245641Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Load test data\ntest_dir = '/kaggle/input/bttai-ajl-2025/test/test'\n#test_generator = preprocess_test_data(test_df, test_dir)\ntest_ds = tf.keras.utils.image_dataset_from_directory(\n  test_df,\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=123,\n  image_size=image_size,\n  batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2025-03-16T14:01:20.920978Z","iopub.execute_input":"2025-03-16T14:01:20.921357Z","iopub.status.idle":"2025-03-16T14:01:20.958600Z","shell.execute_reply.started":"2025-03-16T14:01:20.921328Z","shell.execute_reply":"2025-03-16T14:01:20.957067Z"}}},{"cell_type":"markdown","source":"test_df['file_path'] = test_df['md5hash']  # Assuming test images are in a single directory\n\n# 7. Make Predictions\npredictions = model.predict(test_generator)\npredicted_classes = np.argmax(predictions, axis=1)\n\n# 8. Convert Predictions to Labels\nlabel_encoder = LabelEncoder()\ntrain_df['encoded_label'] = label_encoder.fit_transform(train_df['label'])\ntest_df['predicted_label'] = label_encoder.inverse_transform(predicted_classes)\n\n# Save predictions\ntest_df[['md5hash', 'predicted_label']].to_csv(path_or_buf='/kaggle/working/submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2025-03-10T22:53:02.830431Z","iopub.status.idle":"2025-03-10T22:53:02.830785Z","shell.execute_reply":"2025-03-10T22:53:02.830660Z"}}},{"cell_type":"markdown","source":"## 7. Generate Predictions","metadata":{}},{"cell_type":"code","source":"# TODO\n# Generate predictions based on the trained model\n# Then, save the predictions into a CSV file for submission","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-10T22:53:02.831943Z","iopub.status.idle":"2025-03-10T22:53:02.832441Z","shell.execute_reply":"2025-03-10T22:53:02.832227Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions = s_model.predict(val_ds)","metadata":{"execution":{"iopub.status.busy":"2025-03-16T21:16:33.176482Z","iopub.execute_input":"2025-03-16T21:16:33.176908Z","iopub.status.idle":"2025-03-16T21:16:58.998414Z","shell.execute_reply.started":"2025-03-16T21:16:33.176878Z","shell.execute_reply":"2025-03-16T21:16:58.997237Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predictions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T21:16:59.000099Z","iopub.execute_input":"2025-03-16T21:16:59.000568Z","iopub.status.idle":"2025-03-16T21:16:59.016717Z","shell.execute_reply.started":"2025-03-16T21:16:59.000526Z","shell.execute_reply":"2025-03-16T21:16:59.015457Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_loss, test_accuracy = s_model.evaluate(val_ds)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T21:20:48.712380Z","iopub.execute_input":"2025-03-16T21:20:48.712903Z","iopub.status.idle":"2025-03-16T21:21:13.635288Z","shell.execute_reply.started":"2025-03-16T21:20:48.712861Z","shell.execute_reply":"2025-03-16T21:21:13.634034Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T21:21:47.800686Z","iopub.execute_input":"2025-03-16T21:21:47.801152Z","iopub.status.idle":"2025-03-16T21:21:47.807461Z","shell.execute_reply.started":"2025-03-16T21:21:47.801117Z","shell.execute_reply":"2025-03-16T21:21:47.806262Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test_accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-16T21:21:52.027193Z","iopub.execute_input":"2025-03-16T21:21:52.027669Z","iopub.status.idle":"2025-03-16T21:21:52.034608Z","shell.execute_reply.started":"2025-03-16T21:21:52.027633Z","shell.execute_reply":"2025-03-16T21:21:52.033397Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}